{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim.models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n",
      "\n",
      "parsed_sents \u001b[38;5;241m=\u001b[39m LineSentence(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt_filepath\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "word2vec_local_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintermediate/word2vec_model_all\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "sent_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m parsed_sents])\n",
      "\n",
      "\u001b[38;5;66m# the code below can be time consuming so set to true if you want to train the model.\u001b[39m\n",
      "\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "    \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "    logging\u001b[38;5;241m.\u001b[39mbasicConfig(format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mINFO)\n",
      "    \u001b[38;5;66m# initiate the model and perform the first epoch of training\u001b[39m\n",
      "    localvec \u001b[38;5;241m=\u001b[39m Word2Vec(parsed_sents, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "    localvec\u001b[38;5;241m.\u001b[39msave(word2vec_local_filepath)\n",
      "    \u001b[38;5;66m# perform another 24 epochs of training\u001b[39m\n",
      "    \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m24\u001b[39m):\n",
      "        localvec\u001b[38;5;241m.\u001b[39mtrain(parsed_sents, total_examples\u001b[38;5;241m=\u001b[39msent_count, epochs\u001b[38;5;241m=\u001b[39mlocalvec\u001b[38;5;241m.\u001b[39miter)\n",
      "        localvec\u001b[38;5;241m.\u001b[39msave(word2vec_local_filepath)\n",
      "\n",
      "\u001b[38;5;66m# load the finished models from disk\u001b[39m\n",
      "localvec \u001b[38;5;241m=\u001b[39m Word2Vec\u001b[38;5;241m.\u001b[39mload(word2vec_local_filepath)\n",
      "localvec\u001b[38;5;241m.\u001b[39minit_sims()\n",
      "\u001b[38;5;28;01mprint\u001b[39;00m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalvec, {} training epochs so far.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(localvec\u001b[38;5;241m.\u001b[39mtrain_count)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nates.nlp.w2v_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
